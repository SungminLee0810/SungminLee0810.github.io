---
title: "DETR: End-to-End Object Detection with Transformers"
classes: wide
date: 2020-06-15 00:00:00
sitemap :
categories: Paper_review Object_detection ECCV2020
---

# Introduction:

![image-center]({{ site.url }}{{ site.baseurl }}/assets/images/2020_0615/fig0_intro.png){: .align-center}
우선 DETR은 제목에서도 확인할 수 있는 것처럼 End-to-End로 학습할 수 있는 Object Detection 방법에 대한 논문이다.
DETR은 Facebook AI에서 발표한 논문으로 아직 ECCV 2020의 accepted paper list가 공개되지 않았음에도,
ML 및 CV 커뮤니티로부터 뜨거운 주목을 받고 있다.

이 논문이 주목을 받는 것은 기존 방법들과 차별된 두 가지 이유가 있기 때문이라 생각한다. 
- Anchor를 사용하지 않는다.
- Non-maximum Suppression (NMS)를 사용하지 않는다.

위 두 모듈은 기존 Object Detection 방법들에서는 필수적으로 사용되던 방법이지만, 생각해보면 heuristic의 집약체라 해도 과언이 아니다. 
본 논문에서는 이러한 문제점을 지적하며 Transformer와 Hungarian algorithm을 적용하여,
Anchor와 NMS 조차도 모델이 알아서 해결할 수 있음을 실험적으로 보여주었다.
(시퀀셜 데이터 분석에 유리하다고 알려진 Transformer를 Image 데이터에 적용한 것도 이 논문이 주목을 받은 이유 중 하나가 될 수 있겠다.)

![image-center]({{ site.url }}{{ site.baseurl }}/assets/images/2020_0615/fig1_frcnn_vs_detr.png){: .align-center}
*Fig.1 Faster RCNN과 DETR의 구조적 차이 비교 (source: https://medium.com/swlh/one-stop-for-object-detectors-2c99daa08c50)*

Fig.1은 Faster RCNN과 DETR의 구조적 차이를 도식화하여 표현한 것이다. 
Faster RCNN이 object를 detection 하기 위해서는 CNN feature를 추출한 뒤 region proposal, NMS, 그리고 RoI Align과 같은 domain specific한 복잡한 과정을 거치는 반면,
DETR은 이 모든 과정을 Transformer에 맡겨버린다. 
저자들은 Detection 모델이 학습을 잘하였다면 기존 detection 방법들에 적용하던 heuristic한 과정들을 추론 과정에서 모두 녹여낼 것이라는 가정을 하였을 것이다.
(무책임해 보일 수 있지만 실험 결과를 보면 의도한대로 잘 학습이 되는 것 같다.)

모델의 구조가 간단하니 DETR은 학습 과정도 End-to-End로 간단하게 구현이 가능하다는 것도 장점이라 할 수 있다.
Faster R-CNN을 학습시키기 위해서는 region proposal network과 detector 몇번의 epoch 마다 번갈아가면서 학습을 시켜줘야한다. (저자들의 original 코드 참조)

그러나 DETR에도 몇 가지 개선이 필요한 부분이 있다.
첫째는 학습 시간이다. 전체적인 파이프라인은 간단하지만, Transformer 자체는 복잡한 모델이다. (Transformer에 대한 자세한 설명은 다음 [포스팅](/_posts/2020-06-19-tech-post.md)에서 다룰 예정이다.)
Self-attention을 포함한 encoder-decoder 구조를 하고 있어 학습해야하는 파라미터가 많아, V100을 16장을 쓰고도 학습시간이 3일이나 걸린다고 한다.

둘째는 small object (COCO에서 정의한 small object target)에 대한 detection 성능이 기존 SOTA에 미치지 못하는 점이다. 저자들은 Hungarian Matching과 self-attention 구조가 large object의 포착에는 유리하지만, small object 포착을 위해서는 개선이 필요하다고 밝히고 있다.

이러한 한계점이 존재함에도 나는 DETR이 object detection에 새로운 패러다임을 제시하는 milestone급의 논문이 아닐까하는 생각이 든다.
특히, DETR의 decoder attention을 가시화한 Fig.2에서 두 마리의 코끼리 상당 부분 겹쳐 있음에도, 
어떤 다리가 어느 코끼리의 것인지 구분할 수 있음을 보여주는데, 코끼리의 형상을 완벽하게 학습해내지 않고는 절대 불가능한 task라는 생각이 든다.
그 옆에 있는 얼룩말의 예시에서도 비슷한 특징이 보인다.

![image-center]({{ site.url }}{{ site.baseurl }}/assets/images/2020_0615/fig2_quantitative_result.png){: .align-center}
*Fig.2 DETR의 decoder attention을 가시화한 예시. 모델은 주로 object의 외곽 부분에 집중하고 있다. 각각의 object에 대한 prediction 결과는 각각 다른 color로 표현된다.*

이제는 좀더 상세히 DETR을 들여다 보도록 하겠다.

# Method:
