---
title: "DETR: End-to-End Object Detection with Transformers"
classes: wide
date: 2020-06-15 00:00:00
sitemap :
use_math: true
categories: Paper_review Object_detection ECCV2020
---

# Introduction

![image-center]({{ site.url }}{{ site.baseurl }}/assets/images/2020_0615/fig0_intro.png){: .align-center}

Facebook AI에서 발표한 DETR은 End-to-End로 학습가능한 DEtection 을 위한 TRasnformer를 제안함으로써  
ECCV 2020의 accepted paper list가 공개되지 않은 시점에서도 ML 및 CV 커뮤니티에서 뜨거운 이슈가 되었다.
이 논문이 주목을 받게 된 것은 기존 방법들과 차별된 두 가지 이유가 있었기 때문이다. 
- Anchor를 사용하지 않는다.
- Non-maximum Suppression (NMS)를 사용하지 않는다.

 Anchor와 NMS는 기존 Object Detection 방법들에서는 필수적으로 사용되는 방법이지만,
 아이러니 하게도 data-driven을 지향하는 머신러닝 트렌드와는 맞지 않게 heuristic 그 자체다. 
본 논문에서는 이러한 문제점을 지적하며 Transformer와 Hungarian algorithm을 적용하여,
Anchor와 NMS 조차도 모델이 알아서 해결할 수 있음을 실험적으로 보여주었다.
(시퀀셜 데이터 분석에 유리하다고 알려진 Transformer를 Image 데이터에 적용한 것도 이 논문이 주목을 받은 이유 중 하나가 될 수 있겠다.)

![image-center]({{ site.url }}{{ site.baseurl }}/assets/images/2020_0615/fig1_frcnn_vs_detr.png){: .align-center}
*Fig.1 Faster RCNN과 DETR의 구조적 차이 비교 (source: https://medium.com/swlh/one-stop-for-object-detectors-2c99daa08c50)*

Fig.1은 Faster RCNN과 DETR의 구조적 차이를 도식화하여 표현한 것이다. 
Faster RCNN이 object를 detection 하기 위해서는 CNN feature를 추출한 뒤 region proposal, NMS, 그리고 RoI Align과 같은 domain specific한 복잡한 과정을 거치는 반면,
DETR은 이 모든 과정을 Transformer에 맡겨버린다. 
저자들은 Detection 모델이 학습을 잘하였다면 기존 detection 방법들에 적용하던 heuristic한 과정들을 추론 과정에서 모두 녹여낼 것이라는 가정을 하였을 것이다.
(무책임해 보일 수 있지만 실험 결과를 보면 의도한대로 잘 학습이 되는 것 같다.)

모델의 구조가 간단하니 DETR은 학습 과정도 End-to-End로 간단하게 구현이 가능하다는 것도 장점이라 할 수 있다.
Faster R-CNN을 학습시키기 위해서는 region proposal network과 detector 몇번의 epoch 마다 번갈아가면서 학습을 시켜줘야한다. (저자들의 original 코드 참조)

그러나 DETR에도 몇 가지 개선이 필요한 부분이 있다.
첫째는 학습 시간이다. 전체적인 파이프라인은 간단하지만, Transformer 자체는 복잡한 모델이다. (Transformer에 대한 자세한 설명은 다음 [포스팅](/_posts/2020-06-19-tech-post.md)에서 다룰 예정이다.)
Self-attention을 포함한 encoder-decoder 구조를 하고 있어 학습해야하는 파라미터가 많아, V100을 16장을 쓰고도 학습시간이 3일이나 걸린다고 한다.

둘째는 small object (COCO에서 정의한 small object target)에 대한 detection 성능이 기존 SOTA에 미치지 못하는 점이다. 저자들은 Hungarian Matching과 self-attention 구조가 large object의 포착에는 유리하지만, small object 포착을 위해서는 개선이 필요하다고 밝히고 있다.

이러한 한계점이 존재함에도 나는 DETR이 object detection에 새로운 패러다임을 제시하는 milestone급의 논문이 아닐까하는 생각이 든다.
특히, DETR의 decoder attention을 가시화한 Fig.2에서 두 마리의 코끼리 상당 부분 겹쳐 있음에도, 
어떤 다리가 어느 코끼리의 것인지 구분할 수 있음을 보여주는데, 코끼리의 형상을 완벽하게 학습해내지 않고는 절대 불가능한 task라는 생각이 든다.
그 옆에 있는 얼룩말의 예시에서도 비슷한 특징이 보인다.

![image-center]({{ site.url }}{{ site.baseurl }}/assets/images/2020_0615/fig2_quantitative_result.png){: .align-center}
*Fig.2 DETR의 decoder attention을 가시화한 예시. 모델은 주로 object의 외곽 부분에 집중하고 있다. 각각의 object에 대한 prediction 결과는 각각 다른 color로 표현된다.*

이제 DETR을 조금 더 깊이 들여다 보도록 하겠다.

# <u>Object detection == direct set prediction</u>

저자들은 object detection 문제는 bounding box 좌표와 class label을 한꺼번에 맞춰야하는 set prediction 문제인데,
기존의 방법들이 많은 수의 proposal과 anchor를 통한 indirect set prediction을 하다보니 모델이 복잡해지고, 
후처리 방법에 모델의 성능이 많은 영향을 받을 수 밖에 없음을 시사하였다.
따라서 이러한 한계를 극복하기 위해서는 direct set prediction이 필수적이다.
이런 생각에서 시작된 모델이 DETR이다.

# DETR 모델의 pipeline

저자들은 DETR 모델이 잘 동작 할 수 있게하기 위해 3가지 중요한 요소를 설계한다..


![image-center]({{ site.url }}{{ site.baseurl }}/assets/images/2020_0615/fig3_pipeline.png){: .align-center}
*Fig.3 DETR의 pipeline*

앞서 언급한 것처럼 DETR은 CNN과 Transformer의 조합만으로 Anchor나 NMS의 도움없이 object을 검출해낸다. 
이것이 가능한 것은 모델 학습에 Hungarian Algorithm을 적용하기 때문인데, 
이는 ground truth box와 predicted box가 1대1로 매칭되도록 하여 한 target에 대하여 중복하여 prediction하는 경우를 배제시키기 때문이다.
만약 학습 과정에서 target object를 중복하여 prediction 하게 된다면, 상대적으로 matching 점수가 낮은 predicted box를 'no object' class와 매칭하게 된다.
이런 과정을 학습시 반복하다보면 모델은 자연스럽게 한 물체에 대하여 중복하여 prediction하지 않을 수 있게 된다.

DETR은 모델의 검출 성능을 올리기 위해 한 가지 장치를 더 적용 한다.
그것은 Generalized IoU loss (GIoU loss)이며, 단순히 bounding box의 좌표에 대하여 l1 loss를 적용하였을때보다 훨씬 더 tight 한 boundary의 포착이 가능하도록 한다.
(GIoU에 대한 내용은 후에 다시 다루도록 하겠다.)


# Object detection set prediction loss 
![image-center]({{ site.url }}{{ site.baseurl }}/assets/images/2020_0615/fig4_loss.png){: .align-center}
*Fig.4 Object detection set prediction loss*


# DETR 모델의 구조
![image-center]({{ site.url }}{{ site.baseurl }}/assets/images/2020_0615/fig5_architecture.png){: .align-center}
*Fig.5 Model architecure*

# Details of DETR's Transformer
![image-center]({{ site.url }}{{ site.baseurl }}/assets/images/2020_0615/fig6_detr_transformer.png){: .align-center}
*Fig.6 Details of DETR's Transformer*

# Object queries visualzation
![image-center]({{ site.url }}{{ site.baseurl }}/assets/images/2020_0615/fig9.png){: .align-center}
*Fig.7 Object queries visualzation*

# Intermediate results
![image-center]({{ site.url }}{{ site.baseurl }}/assets/images/2020_0615/fig7.png){: .align-center}

# Quantitative results
![image-center]({{ site.url }}{{ site.baseurl }}/assets/images/2020_0615/fig.11.png){: .align-center}

# Panoptic segmentation results
![image-center]({{ site.url }}{{ site.baseurl }}/assets/images/2020_0615/fig10.png){: .align-center}

# Effect of NMS
![image-center]({{ site.url }}{{ site.baseurl }}/assets/images/2020_0615/fig8.png){: .align-center}


<!-- 위의 두 방법을 한 수식으로 표현하면 다음과 같다.

... 작성중

$$
\mathcal{L}_{box} (b_{i}, \hat{b}_{\sigma(i)})
$$
흥미롭게도 위의 수식은 bipartite matching을 위해서 사용되며,

loss term은 아래와 같다.

... TBU -->